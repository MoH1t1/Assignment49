{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Q1. What is Elastic Net Regression and how does it differ from other regression techniques?\n\nElastic Net Regression combines both L1 regularization (Lasso) and L2 regularization (Ridge). It adds a penalty term to the cost function that is a weighted combination of \nthe L1 and L2 norms of the coefficients. This allows it to benefit from both feature selection (like Lasso) and handling multicollinearity (like Ridge). Elastic Net is particularly \nuseful when there are many correlated features.\n\n# Q2. How do you choose the optimal values of the regularization parameters for Elastic Net Regression?\n    \nThe optimal values of the regularization parameters λ (overall strength of regularization) and α (ratio between L1 and L2 penalties) are typically chosen using cross-validation. \nλ controls the overall penalty strength, while α determines the balance between Lasso and Ridge. Grid search or random search can be used to find the best combination.\n    \n# Q3. What are the advantages and disadvantages of Elastic Net Regression?\n    \nAdvantages:\nCombines the strengths of both Lasso (feature selection) and Ridge (handling multicollinearity).\nWorks well when there are many correlated predictors.\nCan handle situations where the number of predictors exceeds the number of observations.\n\nDisadvantages:\nRequires tuning two hyperparameters (λ and α).\nMay still not perform well if the data has highly nonlinear relationships or interactions between features.\n\n# Q4. What are some common use cases for Elastic Net Regression?\n    \nHigh-dimensional datasets where the number of features is much larger than the number of observations.\nSparse datasets where many features are irrelevant or redundant.\nMulticollinearity scenarios, where predictors are highly correlated.\n\n# Q5. How do you interpret the coefficients in Elastic Net Regression?\n\nThe coefficients in Elastic Net Regression indicate the relationship between each feature and the target variable, similar to Lasso or Ridge. Coefficients shrunk to zero indicate\nfeatures that have been excluded by the model (like in Lasso), while non-zero coefficients reflect important features that are retained in the model.\n\n# Q6. How do you handle missing values when using Elastic Net Regression?\n\nMissing values should be handled before applying Elastic Net Regression, as the model cannot directly handle them. \n\nCommon approaches include:\nImputation (mean, median, mode, or more sophisticated techniques like KNN or regression imputation).\nRemoving rows with missing values, although this can lead to data loss.\n\n# Q7. How do you use Elastic Net Regression for feature selection?\n\nElastic Net automatically performs feature selection by shrinking coefficients of less important features toward zero (Lasso component) and retaining significant features \n(Ridge component). Features with coefficients shrunk to zero are effectively excluded from the model, making Elastic Net useful for feature selection.\n\n# Q9. What is the purpose of pickling a model in machine learning?\n\nPickling a model allows you to save the trained model to disk and load it later for inference without needing to retrain the model. This helps in sharing models,\nmaking predictions in production environments, and saving computational resources.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Q8. How do you pickle and unpickle a trained Elastic Net Regression model in Python?\n# To pickle (save) and unpickle (load) a trained Elastic Net model, use the joblib library, which is efficient for saving models in scikit-learn.\n\n# Pickling:\nimport joblib\njoblib.dump(model, 'elastic_net_model.pkl')\n\n# Unpickling:\nmodel = joblib.load('elastic_net_model.pkl')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}